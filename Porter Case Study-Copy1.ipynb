{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d0284d",
   "metadata": {},
   "source": [
    "# Porter Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f1777",
   "metadata": {},
   "source": [
    "                                      Important Library For Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a059ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "from scipy.stats import zscore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bd918",
   "metadata": {},
   "source": [
    "Q.1. (a). the Problem Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Problem_Statement.jpeg\", width = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42dfc6d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Porter, India's largest marketplace for intra-city logistics, works with a wide range of \n",
    "restaurants to deliver their items directly to customers. The company wants to estimate the \n",
    "delivery time for each order based on various features, such as the items ordered, the restaurant, \n",
    "and the availability of delivery partners. An accurate estimation of delivery time will enhance \n",
    "customer satisfaction and optimize the delivery process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbae4e",
   "metadata": {},
   "source": [
    "# 1. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Eda.jpg\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968fdb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.1(b). Importing Data \n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Mustafa Hussain\\Desktop\\Placement Test\\dataset.csv\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e32c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# top 5 rows \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92427b79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bottom 5 rows\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effe4e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Statical View of data of numerical data\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dfd6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statical View of categorical data\n",
    "\n",
    "df.describe(include = \"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdcf26",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Q.1(c). Data Structure\n",
    "    \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af885b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infomation/summary of data\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null values in dataset\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97489bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We have multiple columns where the we got the missing values we have to impute it.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac808c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"market_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319028be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since our market_id column has the 6 unique market id and the missing value in the 987 rows which are very less\n",
    "if we compare it with our whole dataset where all 197428 rows so  we can use the\n",
    "random method to impute this missing values.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_market_id = df.market_id.dropna().values\n",
    "\n",
    "df[\"market_id\"]  = df[\"market_id\"].apply(lambda x : np.random.choice(non_null_market_id) if pd.isnull(x) else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ce5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We imputed the missing values in the \"market_id\" column.\n",
    "\n",
    "df[\"market_id\"].isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"actual_delivery_time\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f772e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputting missing values in the \"actual_delivery_time\" column.\n",
    "\n",
    "'''\n",
    "Here we have only 7 rows Containg null values  in the \"actual_delivery_time\" column and also the data is in TimeSeries and Continuous \n",
    "so we can Impute it with ffill or bfill.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"actual_delivery_time\"] = df[\"actual_delivery_time\"].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We imputed the missing values in the \"actual_delivery_time\" column.\n",
    "\n",
    "df[\"actual_delivery_time\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ca4ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"store_primary_category\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"store_primary_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputting missing values in the \"store_primary_category\" Column.\n",
    "\n",
    "'''\n",
    "Since our \"store_primary_categroy\" column has 4760 missing rows and the 74 unique data in the columns if \n",
    "we compare it with our whole datase i.e, the 197428 rows and 14 columns these missing values are very few \n",
    "so we can impute it with the high occurence of the data i.e, the mode() method.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21222611",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_value = df[\"store_primary_category\"].mode()[0]\n",
    "\n",
    "df[\"store_primary_category\"].fillna(mode_value, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76f326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we imputted the missing values in the \"store_primary_category\" column.\n",
    "\n",
    "df[\"store_primary_category\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42591da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputting missing values in the \"order_protocol\" Column.\n",
    "\n",
    "df[\"order_protocol\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef6541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"order_protocol\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a28350",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since our \"order_protocol\" column has the 995 rows missing and the 7 unique values present there\n",
    "so we can impute it with the ffill or bfill.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2bc36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"order_protocol\"] = df[\"order_protocol\"].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We imputted the missing value in the \"order_protocol\" Column.\n",
    "df.order_protocol.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values in the [[\"total_onshift_partners\", \"total_busy_partners\", \"total_outstanding_orders\"]] Columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f495ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total null values  in the total_onshift_partners column : \", df.total_onshift_partners.isnull().sum())\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(df.total_onshift_partners.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887c3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total null values  in the total_busy_partners column : \", df.total_busy_partners.isnull().sum())\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(df.total_busy_partners.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb104a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total null values in the total_outstanding_orders column : \", df.total_outstanding_orders.isnull().sum())\n",
    "print(\"--------------------------------------------------------------------------------------------------------\")\n",
    "print(df.total_outstanding_orders.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0be64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_outstanding_orders.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f06542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statical View of the [[\"total_onshift_partners\", \"total_busy_partners\", \"total_outstanding_orders\"]] Columns.\n",
    "\n",
    "df[[\"total_onshift_partners\", \"total_busy_partners\", \"total_outstanding_orders\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since our above all three columns have the  16262 rows contain the null values and also these are the \n",
    "numerical columns and rows containing values like \n",
    "\n",
    "total_onshift_partners   : 172 unique values,\n",
    "total_busy_partners      : 159 unique values,\n",
    "total_outstanding_orders : 281 unique values\n",
    "\n",
    "\n",
    "By the above Statical view Observation we can say that several similarites between the columns like\n",
    "each column has 181166 entries, mean vary between the 41-58, standard deviation also vary between  32-52, \n",
    "min vary between -4 to -6, max vary between 154 to 285 and the Quartile range also the same.\n",
    "\n",
    "\n",
    "So We Can Impute missing values  all three columns with same method i.e, the random method.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255cc5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(column):\n",
    "    non_null_values = column.dropna().values\n",
    "    return column.apply(lambda x : np.random.choice(non_null_values) if pd.isnull(x) else x)\n",
    "    \n",
    "    \n",
    "df[\"total_onshift_partners\"] = random_sampling(df[\"total_onshift_partners\"])\n",
    "df[\"total_busy_partners\"]    = random_sampling(df[\"total_busy_partners\"])\n",
    "df[\"total_outstanding_orders\"] = random_sampling(df[\"total_outstanding_orders\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4764c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We Imputed the all null values from the  our dataset.  \n",
    "\n",
    "print(\"Total Null values in the total_onshift_partners columns :\", df[\"total_onshift_partners\"].isnull().sum())\n",
    "print(\"Total Null values in the total_busy_partners columns : \",  df[\"total_busy_partners\"].isnull().sum())   \n",
    "print(\"Total Null values in the total_outstanding_orders columns :\",  df[\"total_outstanding_orders\"].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e01c24",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Data Preprocessing and Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\DataPreprocessing_And Feature_Engg.jpg\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bbeb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating new features \"TimeTakenForDelivery\" With the help of \"Created_at\" and \"actual_delivery_time\" columns.\n",
    "\n",
    "df[\"created_at\"] = pd.to_datetime(df.created_at, errors = \"coerce\")\n",
    "df[\"actual_delivery_time\"] = pd.to_datetime(df.actual_delivery_time, errors = \"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "df[\"TimeTakenForDelivery\"] =  df[\"actual_delivery_time\"]- df[\"created_at\"] \n",
    "df[\"TimeTakenForDelivery\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69144e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TimeTakenForDelivery\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f89934",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "By the statical view of the \"TimeTakenForDelivery\" Column Observations are\n",
    "\n",
    "minimum  time to delivered to any product is -23 days and\n",
    "maximum time to delivered to any product is 98 days \n",
    "\n",
    "which is kind of impossible thing bcz time not be in the negative\n",
    "So, these are the outliers and we have to remove it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a9aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are removing the ouliers with Quarantile range\n",
    "\n",
    "df[\"TimeTakenForDelivery_Seconds\"] = df[\"TimeTakenForDelivery\"].dt.total_seconds()\n",
    "Q1 = df[\"TimeTakenForDelivery_Seconds\"].quantile(0.25)\n",
    "Q3 = df[\"TimeTakenForDelivery_Seconds\"].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR \n",
    "\n",
    "df[\"TimeTakenForDelivery_Seconds\"] = np.where(\n",
    "(df[\"TimeTakenForDelivery_Seconds\"] < lower_bound) | (df[\"TimeTakenForDelivery_Seconds\"] > upper_bound),\n",
    "    np.nan, df[\"TimeTakenForDelivery_Seconds\"]\n",
    ")\n",
    "\n",
    "df[\"TimeTakenForDelivery\"] = pd.to_timedelta(df[\"TimeTakenForDelivery_Seconds\"], unit = 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3508280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After removing outliers we got 6285 rows havig missing value, so we need to impute it.\n",
    "\n",
    "df[\"TimeTakenForDelivery\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e73d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our dataset is  datetime format and the best method is impute missing value in timeseries dataset is ffill or bfll so we can use  one of them.\n",
    "\n",
    "df[\"TimeTakenForDelivery\"].ffill(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8646d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we imputed all missing value from of our dataset.\n",
    "df[\"TimeTakenForDelivery\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa84211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our dataset is  datetime format and the best method is impute missing value in timeseries dataset is ffill or bfll so we can use  one of them.\n",
    "\n",
    "df[\"TimeTakenForDelivery_Seconds\"].ffill(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TimeTakenForDelivery_Seconds\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f83596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statical View of \"TimeTakenForDelivery\" Column.\n",
    "df[\"TimeTakenForDelivery\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad56c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Following are the Observations of the \"TimeTakenForDelivery\"  Columns.\n",
    "\n",
    "Average time taken to delivered per per product ≈46 minutes,\n",
    "Minimum time taken to delivered  any product    ≈4 minutes,\n",
    "maximum time taken to delivered  any product    ≈89 minutes\n",
    "maximu i.e, 75%(Product) delivered within the   55 minutes.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23029bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new features \"HourOfDay\", \"DayOfWeek\", \"Month\"\n",
    "\n",
    "df[\"HourOfDay\"] = df[\"created_at\"].dt.hour\n",
    "df[\"DayOfWeek\"] = df[\"created_at\"].dt.dayofweek\n",
    "df[\"month\"]   = df[\"created_at\"].dt.month\n",
    "df[\"week\"] = df[\"created_at\"].dt.isocalendar().week\n",
    "df[\"year\"]  = df[\"created_at\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting new features like \"TimeTakenForDelivery_Minutes\" and \"TimeTakenForDelivery_Hours\"\n",
    "\n",
    "df[\"TimeTakenForDelivery_Minutes\"]  =    df[\"TimeTakenForDelivery\"].dt.total_seconds()/60\n",
    "df[\"TimeTakenForDelivery_Hours\"]    =    df[\"TimeTakenForDelivery\"].dt.total_seconds()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621fafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting new features from \"Delivery_categories\" as how how fast and slow we are able to deliver the product.\n",
    "'''\n",
    "Since we have all time format like [\"TimeTakenForDelivery_Seconds\", \"TimeTakenForDelivery_Minutes, \n",
    "TimeTakenForDelivery_Hours\"] but we can extract this feature with the help of minutes bcz maximum, and average\n",
    "delivery time fall within the hour.\n",
    "\n",
    "'''\n",
    "\n",
    "df[\"Delivery_Categories\"] = pd.cut(df[\"TimeTakenForDelivery_Minutes\"], \n",
    "                                   bins = [3, 30, 40, 60, 90], \n",
    "                                   labels = [\"Fast\", \"Moderate\", \"Slow\", \"Very Slow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21dd444",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Here we can see that the our maximum order delivered  come inside Slow Categories and\n",
    "less order are in the fast and moderate categories.\n",
    "'''\n",
    "\n",
    "df[\"Delivery_Categories\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new features like how much time taken per item for delivered.\n",
    "\n",
    "df[\"DeliverySpeedPerItem\"] = df[\"TimeTakenForDelivery_Minutes\"] / df[\"total_items\"]\n",
    "df[\"DeliverySpeedPerItem\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f9470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are extracting the features like \"AvgItemPrice\".\n",
    "\n",
    "df[\"AvgItemPrice\"] = df[\"subtotal\"] / df[\"total_items\"]\n",
    "df[\"AvgItemPrice\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b640701b",
   "metadata": {},
   "source": [
    "                 ●\tEncoding categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categorical_df = df.select_dtypes(include = \"object\")\n",
    "\n",
    "Encoded_Categorical_df = pd.get_dummies(Categorical_df, drop_first = True)\n",
    "\n",
    "'''\n",
    "Since we Encoded our all categorical columns like  \"store_id\", \"store_primary_category\" \n",
    "that's the reason we have many columns in Encoded_Categorical_df so the memory usage by data is 1.3 GB.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoded_Categorical_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7bd4a",
   "metadata": {},
   "source": [
    "# 3. Data Visualization and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d270a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Data Visualization.jpg\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b91f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since We Cleaned our dataset previously so don't need to clean it again if we feel \n",
    "some thing which can corrected and add on we will do it further.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to identify the how the Delivery Categories Data distributed.\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "sns.countplot(x = \"Delivery_Categories\", data = df, palette = \"viridis\")\n",
    "plt.title(\"Delivery Catergroies Count\")\n",
    "plt.xlabel(\"Delevery_Categories\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we can see that the our maximum product come inside the slow, moderate categoreis and less are come\n",
    "inside the very slow, fast categories respectively.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"subtotal\"] = pd.to_numeric(df[\"subtotal\"], errors = \"coerce\")\n",
    "df[\"TimeTakenForDelivery_Minutes\"] = pd.to_numeric(df[\"TimeTakenForDelivery_Minutes\"], errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5703d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we are identifying the pattern of subtotal and total_time time taken in delivery with the bifarcation of Delivery_categories.\n",
    "\n",
    "plt.figure(figsize = (12, 6))\n",
    "\n",
    "sns.scatterplot(x =\"subtotal\", y = \"TimeTakenForDelivery_Minutes\", data = df, hue = \"Delivery_Categories\", alpha = 0.5)\n",
    "plt.title(\"Subtotal Vs TimeTakenForDelivery_Minutes\")\n",
    "plt.xlabel(\"Subtotal\")\n",
    "plt.ylabel(\"TimeTakenForDelivery_Minutes\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33cc62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "\n",
    "sns.boxplot(data = df, y = \"TimeTakenForDelivery_Minutes\", \n",
    "              x = \"Delivery_Categories\", palette = \"Set2\" )\n",
    "plt.title(\"Delivery Time Distribution by Categories\")\n",
    "plt.xlabel(\"Delivery_Categoreis\")\n",
    "plt.ylabel(\"Delevery Time in Minutes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TimeTakenForDelivery_Minutes\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7efd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "After the analysis of Scatter plot and Box we can say that the some of the ouliers in \"TimeTakenForDelivery_Minutes\" Column\n",
    "also the Statical view indicate that then we have to eliminate the outliers.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing ouliers with the help of interquartile range(IQR)\n",
    "\n",
    "\n",
    "Q1 = df[\"TimeTakenForDelivery_Minutes\"].quantile(0.25)\n",
    "Q3 = df[\"TimeTakenForDelivery_Minutes\"].quantile(0.75)\n",
    "\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df[\"TimeTakenForDelivery_Minutes\"] = np.where(\n",
    "    (df[\"TimeTakenForDelivery_Minutes\"] < lower_bound) | (df[\"TimeTakenForDelivery_Minutes\"] > upper_bound),\n",
    "                                              np.nan,df[\"TimeTakenForDelivery_Minutes\"])\n",
    "\n",
    "df[\"TimeTakenForDelivery_Minutes\"] = pd.to_timedelta(df[\"TimeTakenForDelivery_Minutes\"], unit = \"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f241c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we removed outliers from the colmns that's the reason we receving missing values in 1335 columns we have to impute it.\n",
    "\n",
    "df[\"TimeTakenForDelivery_Minutes\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51426a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our column containing timeseries data and as we know best suited for this ffill|bfll.\n",
    "\n",
    "df[\"TimeTakenForDelivery_Minutes\"].bfill(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1943d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We imputed all missing values from the columns.\n",
    "\n",
    "df[\"TimeTakenForDelivery_Minutes\"].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a58247",
   "metadata": {},
   "source": [
    "                         ●\tPlotting the data again to see improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f26244",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(x = \"Delivery_Categories\", data = df, palette = \"magma\")\n",
    "plt.title(\"Delivery Categories Count\")\n",
    "plt.xlabel(\"Delivery_Categories\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "sns.scatterplot(x = \"subtotal\", y = \"TimeTakenForDelivery_Minutes\", hue = \"Delivery_Categories\", data = df, \n",
    "                palette = \"inferno\", alpha = 0.5)\n",
    "plt.title(\"Subtotal Vs TimeTakenForDelivery_Minutes\")\n",
    "plt.xlabel(\"Subtotal\")\n",
    "plt.ylabel(\"TimeTakenForDelivery_Minutes\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since We removed ouliers from the \"TimeTakenForDelivery_Minutes\"  So this is the clear graphical representation of our data.\n",
    "But after the analyze of \"subtotal\" and \"TimeTakenForDelivery_Minutes\" we can say that the these are not strongly corelated\n",
    "bcz geneally in correlation both are increasing or decreasing that means the positive corelation and negative corelation.\n",
    "\n",
    "But in our case it's the constant like \"subtotal\" amount is 10000 but the \"TimeTakenForDelivery_Minutes\" is the same as \n",
    "\"subtotal\" amount is 5000 there no chaninging like positively or negatively.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79151f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "sns.boxplot(x = \"Delivery_Categories\", y = \"TimeTakenForDelivery_Minutes\", data = df, palette = \"twilight\")\n",
    "plt.title(\"Delivery Categories VS TimeTakenForDelivery_Minutes\")\n",
    "plt.xlabel(\"Delivery Categories\")\n",
    "plt.ylabel(\"TimeTakenForDelivery_Minutes\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558942ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "After removing outlier we get the clear picture view of our data but you can see in the Fast Categories There  are some  \n",
    "points which are the outside of whishkers but these aren't outliers, bcz box plot follow the InterQuarntilerange(IQR)\n",
    "\n",
    "\n",
    "Thats  means the  middle line of the box plot is 50(percentile), lower than the middle line is 25(percentile) that is lower_bound\n",
    "and upper than the middle line is 75(percentile) that is upper_bound.\n",
    "\n",
    "and as we know the \n",
    "upper_bound = Q3(75 percentile) + 1.5 * IQR,\n",
    "lower_bound =  Q1(25 percentile) - 1.5 * IQR\n",
    "\n",
    "So in our case it might be possible the bins and labels we calculated that are excedd this upper and lower bound \n",
    "that's the region we are receving outliers.\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c8c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"order_protocol\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5355286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TimeTakenForDelivery_Minutes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56752e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we are trying to find how \"order_protocol\" and \"TimeTakenForDelivery_Minutes\" effecting perfomance of our Buisness.\n",
    "\n",
    "df[\"TimeTakenForDelivery_Minutes\"] = df[\"TimeTakenForDelivery_Minutes\"].dt.total_seconds()/60\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.violinplot(x = \"order_protocol\", y = \"TimeTakenForDelivery_Minutes\", data = df, palette = \"inferno\")\n",
    "plt.xlabel(\"Order Protocol\")\n",
    "plt.ylabel(\"TimeTakenForDelivery_Minutes\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43274f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot is the Combination of box plot an KDE plot Where \n",
    "'''\n",
    "white Dot indicates the median(),\n",
    "Thick black bar indicates the IQR,\n",
    "thin black bar indicates the NonOutLier values\n",
    "and the width of violinplot indicates the density of the data\n",
    "where widest part indicates the maximum density.\n",
    "\n",
    "'''\n",
    "# in our case following are the observations\n",
    "'''\n",
    "maximum order delivered falls between the 40 to 50 minutes and the \"order_protocol: 6.0 shows the more versality\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a733e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are trying to find how \"order_protocol\" and \"TimeTakenForDelivery_Minutes\" bifarcation of \"Delivery_Categories\"\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.barplot(x=\"order_protocol\", y=\"TimeTakenForDelivery_Minutes\",hue = \"Delivery_Categories\", data=df)\n",
    "plt.legend(title = \"Time Taken for delivery by order protocol\", bbox_to_anchor = (1.05, 1), loc = \"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21215af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# patterns and trends\n",
    "\n",
    "plt.figure(figsize = (9, 4))\n",
    "sns.lineplot(x = \"HourOfDay\", y = \"TimeTakenForDelivery_Minutes\", data = df, hue = \"Delivery_Categories\")\n",
    "plt.title(\"Delivery time by Hour of Day and Delivery Categories\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Time taken for delivery in Minutes\")\n",
    "plt.legend(title = \"Delivery Categories\",bbox_to_anchor = (1.05,1),  loc = \"upper left\")\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3fecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# following are the observations of linePlot\n",
    "'''\n",
    "Blue(Fast) most order delivered in fast section within between the 20 and 30 minutes\n",
    "yellow(moderate) all the  order delivered in moderate section between the 30 and 40 minutes\n",
    "greeen(slow) all the order delivered in slow section between 50 and 60 minutes and the last\n",
    "red(very slow) section order delivered more than 70 minutes.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37aaa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are looking for the how \"total_busy_partners\" and \"market_id\" columns are releated to each other.\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.violinplot(x = \"market_id\", y = \"total_busy_partners\", data = df, palette = \"viridis\")\n",
    "plt.xlabel(\"Market ID\")\n",
    "plt.ylabel(\"Total Busy Partners\")\n",
    "plt.xticks(rotation = 45)             \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to find the how our service/product releated to on \"min_item_price\", \"AvgItemPrice\" and \"max_item_price\".\n",
    "\n",
    "fig, axes = plt.subplots(1, 3,figsize = (15, 5))\n",
    "\n",
    "sns.histplot(x = \"AvgItemPrice\", data = df, palette = \"viridis\", ax = axes[0], kde = True, bins = 5)\n",
    "axes[0].set_title(\"Average Item Price\")\n",
    "\n",
    "sns.histplot(x = \"min_item_price\", data = df, color = \"red\", ax = axes[1], kde = True, bins = 5)\n",
    "axes[1].set_title(\"Minimum Item Price\")\n",
    "\n",
    "sns.histplot(x = \"max_item_price\", data = df, color = \"green\", ax = axes[2], kde = True, bins = 5)\n",
    "axes[2].set_title(\"Maximum Item Price\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df51353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "By the observations of \"AvergareItemPrice\", \"MimimumItemPrice and \"MaximumItemPrice\", we can say that the \n",
    "our all three are similar means in \"AvgItemPrice\", maximum product/services are in range 0-2000 like the \"MinimuItemPrice\", and\n",
    "\"maxItemPrice\".\n",
    "\n",
    "So our maximum revenue comes from the \"MimimumItemPrice\" and very less revenue from the \"MaxItemPrice\" \n",
    "our product/servieces Budget Friendly and best suited for middle class family.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c56b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are trying to find the Distribution Of Market id By Order Protocol\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "sns.boxplot(x =\"market_id\", y = \"order_protocol\", data = df, palette = \"magma\")\n",
    "plt.title(\"Distribution Of Market id Via Order Protocol\")\n",
    "plt.xlabel(\"Market ID\")\n",
    "plt.ylabel(\"Order Protocol\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94146377",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we are looking how  \"total_outstanding_orders\" and \"total_busy_partners\" are affecting our services.\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize = (8, 4))\n",
    "\n",
    "sns.histplot(x = \"total_busy_partners\", data = df, kde = True, bins = 10, ax = axes[0], color = \"green\")\n",
    "axes[0].set_title(\"Total Busy Partners\")\n",
    "\n",
    "sns.histplot(x = \"total_outstanding_orders\", data = df, kde = True, bins = 10, ax = axes[1], palette = \"red\")\n",
    "axes[1].set_title(\"Total Outstanding Orders\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations are following of the \"TotalBusyPartners\" and \"TotalOutsandingOrders\"\n",
    "\n",
    "#\ttotal_busy_partners: Number of delivery partners attending to other tasks\n",
    "'''\n",
    "Since our \"TotalBusyPartners\" fall within 0-160 the maximum and peak \"TotalBusyPartners\" is 20 and count more than 50000\n",
    "after that second most \"TotalBusyPartners\" ≈ 15 and count is ≈ 35000.\n",
    "'''\n",
    "\n",
    "\n",
    "#\ttotal_outstanding_orders: Total number of orders to be fulfilled at that moment\n",
    "'''\n",
    "Since our \"TotalOutstandingOrders\" fall between  0-250 and maximum \"TotalOutstandingOrders\"  deliver at ≈30 and count ≈65000\n",
    "and second most \"TotalOutstandingOrders\" at  ≈ 40 and frequency  is ≈ 50000. \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07aa871",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.barplot(x=\"market_id\", y=\"total_busy_partners\", hue = \"Delivery_Categories\", data=df)\n",
    "plt.title(\"Average Number of Busy Partners per Market\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e958b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include = [np.number])\n",
    "corr = numeric_df.corr()\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    " \n",
    "sns.heatmap(corr, annot = True, cmap = \"coolwarm\", fmt = \"0.2f\", \n",
    "            linewidth = 0.5, linecolor = 'green', cbar_kws = {\"shrink\" : 0.8}, annot_kws = {\"size\" : 10})\n",
    "plt.title(\"Correalation Heatmap\", fontsize = 16)\n",
    "plt.xlabel(\"Features\", fontsize = 14)\n",
    "plt.ylabel(\"Features\", fontsize = 14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a52fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we can see that  correlation between all features in the heatmap \n",
    "(a). The Darker color represents the feature is highly corelated, lighter color indicates the less corelated to each other \n",
    "and white color is indicate the no corelation or the almost neglible corelation between the features.\n",
    "\n",
    "(b). The highly corelated represents with the positive (1), highly negative corelated represents with the negative (-1) \n",
    "and the neglible corelation represents with the (0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77bcf33",
   "metadata": {},
   "source": [
    "# 4(a). Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45823523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Insight.jpg\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b3e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(1).Delivery Speed : our most Delivery Categories fall inside the \"slow\", \"moderate\" and very less come inside the \n",
    "                  \"fast\",\"very slow\" categories. also  \"HourOFDay\" at peak some time not able to handle the customers.\n",
    "                  having high \"num_distinct_items\"  takes more time to deliver the product.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b920fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(2).Total Busy Partners and  Total OutStanding Orders: at the peak performance \"TotalBusyPartners\" are less and other time \n",
    "                                                       there much more \"partnres\" also the \"TotalOutStandingOrders comes\n",
    "                                                       between the 0-40.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(3).Customer Spending and Item Trends : our maximum customer are in the minimum categroies and services they are using which\n",
    "                                        Budegt friendly, so we can say that our product is generally use by middle class family.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(4).Market and Total Busy Partners : in market id \"2.0\" and \"4.0\" high freqency and the servieces  in the high density \n",
    "                                     these two market have high demand and rest of all are the in the general \n",
    "                                     but we are not able to full fill the demand bcz here we delivered maximum order in\n",
    "                                     \"moderate\" and \"slow\" Categories.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff308c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(5).Store and Market :store are releated on the market we observed that the market highly coreleated to the market bcz \n",
    "                      in the bifarcation of \"Delivery_Categories\" we got the maximum order are fall in the \"slow\" categories.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83301c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(6).Order Proctol and Partner Effciency : in some protocol we are able to handle the delivery but in some we are not bcz we \n",
    "                                          our onshift parners are less and not full fill the demand.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488852f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(7).Operational Efficency : A high number of \"total_OutSatanding_Orders\" are releated to delayed delevires specially in the \n",
    "                            \"TotalBusyPartners\" during the peak hour we don't have enough work force to handle the volume of \n",
    "                            orders.\n",
    "                            There are Seven(7) \"Orde_protcol\" that's the reason we have verify Orders coming from where like\n",
    "                           through Porter,call to restaurant, pre-booked, third-party, etc. all these thing taking to much time.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e6fe4a",
   "metadata": {},
   "source": [
    "# 4(b). Recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6150f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Recommendations.png\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(1).Delivery Speed Optimization : most of our fall in \"moderate\" and \"slow\" category and in peak hour we are not able to \n",
    "                                  full fill the demand.\n",
    "                                  \n",
    "                                  We can increase the staff during the peak hour and ensure there are enough delivery partners\n",
    "                                  at peak hours we adjust this to give over time to the delivery partners.\n",
    "                                  \n",
    "                                  implement incentive program for those delivery who frequently delivered product in the fast\n",
    "                                  Category, this can boost overall speed and keep partners to motivate and redirect their root.\n",
    "                                  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02046c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(2).Flexible workhour : Offers flexible work hour to the delivery partners, allow them to work at the peak hours \n",
    "                        handle the work and reduce the totalOutstandingOrders.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b308ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(3).Customer Segmentation and Targeting : Since Our customer is budget consious and specially middle class.\n",
    "\n",
    "                                        introduce the premium services for premium customer those who pay for the\n",
    "                                        superfast delivery orders.\n",
    "                                        \n",
    "                                        provide the some discount in the premium services during the non peak hours.\n",
    "                                        we can introduce the customer loyality program for the customer those who are \n",
    "                                        frequently orders and refer their freinds give them the rewards or offer premium\n",
    "                                        services at more discount.\n",
    "                                        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(4).Market Specific Starategdy : in market 4.0 and market 6.0 high demand and we are not able full fill it also our \n",
    "                                 Delivery Category is slow.\n",
    "                                 \n",
    "                                 Assign more delivery partners and resources during the peak hours partnership with local retails\n",
    "                                 to take geographic advantages.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f979687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(5).Store Level Improvement : Stores are highly corelated with the speed of delivery in slow Categories.\n",
    "                              Regulary audit the high volume orders and why is it slow that means\n",
    "                              in preparation time, inventory management, order processing or something for causing the delays.\n",
    "                              \n",
    "                              work with stream  line and give the clear instuction and provide training if it necessary,\n",
    "                              introduce the incentive for who those delivered the high volume product in fast Category.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef31b371",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(6).Improving Order protocol Efficency : Some order protocols types are more efficent and some are stuggling to fullfil their \n",
    "                                         orders due to the lack of partners.\n",
    "                                         \n",
    "                                         introduce streamline protocols and assign the protocols types like directly pre-booked,\n",
    "                                         and third party protocols automatically ordered no need to manual verification and\n",
    "                                         confiramtion. \n",
    "                                         introduce the AI which assign the assigment of Orders equally or less dependent on a \n",
    "                                         special Store.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07068f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(7). Customer Satisfacion Initiatives : Delay and slower services in some category leading to lower customer satisfaction.\n",
    "\n",
    "                                        implement a feedback mechanism where customer can give the real time feedback and\n",
    "                                        after use this data we can identify what is most concern of customer\n",
    "                                        as delivey speed or the better communication.\n",
    "                                        \n",
    "                                        provide real time tracking system and estimated time to deliverd the product also\n",
    "                                        inform them if in case the product will deliver late, this all above mentioned things\n",
    "                                        reduce the customer frustration during the peak workhour.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(8).Long-Term Growth Strategies : as demand grows particulary high market invest in growing force of delivery partners.\n",
    "                                  we can use predictive model to to predict where the demand will increase and according\n",
    "                                  to them we will prepare.\n",
    "                                  \n",
    "                                  strengthen releationships with stores and delivery partners provide the analyis and insight\n",
    "                                  of their performance this will help to improve their work and as well as customer behaviour \n",
    "                                  and improve customer satifaction rate.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31f9e3",
   "metadata": {},
   "source": [
    "# Basic Questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Basic Quesions.jpg\", width = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d275e3b4",
   "metadata": {},
   "source": [
    " 1. Data Structure and Overview\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59192fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.What is the shape of the dataset (number of rows and columns)?\t\n",
    "\n",
    "df.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39331791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.What are the data types of each column?\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Are there any missing values in the dataset? If so, how many and in which columns?\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "'''\n",
    "at the intial investigaion some null value were present in oure dataset but we already impute it\n",
    "at present there no missing values in our dataset.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f937755",
   "metadata": {},
   "source": [
    "2. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What are the basic statistical summaries (mean, median, standard deviation) for the numerical features?\n",
    "\n",
    "df.describe() # By defalult descbre() gives statical summaries of numerical feartures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a512757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What is the distribution of the categorical variables like store_primary_category and order_protocol?\n",
    "\n",
    "categorical_df = df.select_dtypes(include = \"object\")\n",
    "categorical_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ace46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What is the distribution of the categorical variables like store_primary_category and order_protocol?\n",
    "\n",
    "store_primary_category_dist = df['store_primary_category'].value_counts()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=store_primary_category_dist.index, y=store_primary_category_dist.values, palette=\"inferno\")\n",
    "plt.title('Distribution of Store Primary Categories')\n",
    "plt.xlabel('Store Primary Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "order_protocol_dist = df['order_protocol'].value_counts()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=order_protocol_dist.index, y=order_protocol_dist.values, palette=\"inferno\")\n",
    "plt.title('Distribution of Order Protocols')\n",
    "plt.xlabel('Order Protocol')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3bf38b",
   "metadata": {},
   "source": [
    "                                 3. Datetime Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a385f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. How many orders were placed each day/week/month?\n",
    "print(\"Total Order placed in each day :\", df[\"DayOfWeek\"].value_counts())\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"Total Order Placed in each week :\", df[\"week\"].value_counts())\n",
    "print(\"*\"*80)\n",
    "\n",
    "\n",
    "print(\"Total Order Placed in each month :\", df[\"month\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69119ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.What is the distribution of order times throughout the day?\n",
    "\n",
    "HourOfDay_dist = df[\"HourOfDay\"].value_counts().sort_index()\n",
    "sns.barplot(x = HourOfDay_dist.index, y = HourOfDay_dist.values, palette = \"viridis\")\n",
    "plt.title(\"Distribution of day\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation = 90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820688a",
   "metadata": {},
   "source": [
    "                                      4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Feature-Engineering-Feature.jpg\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c62d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. How can we create a new feature for the time taken for each delivery?\n",
    "\n",
    "'''Since we alreay created the \"TimeTakenForEachDelivery\" so don't need to create again.'''\n",
    "\n",
    "df[\"DeliverySpeedPerItem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. How can we extract additional features from the datetime columns, such as the hour of the day or the day of the week?\n",
    "\n",
    "'''Since we alreay created the these feature so don't need to it create again.'''\n",
    "\n",
    "print(df[\"HourOfDay\"])\n",
    "\n",
    "print(\"*\"*80)\n",
    "\n",
    "print(df[\"DayOfWeek\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c2c71",
   "metadata": {},
   "source": [
    "                                    5. Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd28e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Exploratory-Data-Analysis.jpg\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736585da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What are the distribution plots for continuous variables like total_items, subtotal, min_item_price, and max_item_price? \n",
    "\n",
    "fig,axes = plt.subplots(2, 2, figsize = (12, 6))\n",
    "\n",
    "# Plotting Distibution plot of \"total_items\"\n",
    "sns.distplot(x = df[\"total_items\"], ax = axes[0, 0], color = \"green\", bins = 5)\n",
    "axes[0, 0].set_title(\"Distribution Of Total Items\")\n",
    "axes[0, 0].set_xlabel(\"Total Items\")\n",
    "axes[0, 0].set_ylabel(\"Density\")\n",
    "\n",
    "\n",
    "# Plotting Distribution plot of \"subtotal\"\n",
    "sns.distplot(x = df[\"subtotal\"], ax = axes[0, 1], color = \"red\", bins = 5)\n",
    "axes[0, 1].set_title(\"Distribution Of Subtotal\")\n",
    "axes[0, 1].set_xlabel(\"Subtotal\")\n",
    "axes[0, 1].set_ylabel(\"Density\")\n",
    "\n",
    "\n",
    "\n",
    "# Plotting Distribution plot of \"mim_item_price\"\n",
    "sns.distplot(x = df[\"min_item_price\"], ax = axes[1, 0], color = \"navy\", bins = 5)\n",
    "axes[1, 0].set_title(\"Distribution Of Mimimum Item Price\")\n",
    "axes[1, 0].set_xlabel(\"Mimimum Item price\")\n",
    "axes[1, 0].set_ylabel(\"Density\")\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# Plotting Distribution plot of \"max_item_price\"\n",
    "sns.distplot(x = df[\"max_item_price\"], ax = axes[1, 1], color = \"orange\", bins = 5)\n",
    "axes[1, 1].set_title(\"Distribution Of maximum Item Price\")\n",
    "axes[1, 1].set_xlabel(\"Maximum Item Price\")\n",
    "axes[1, 1].set_ylabel(\"Density\")\n",
    "\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f63d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.2 What are the count plots for categorical variables like store?\n",
    "\n",
    "plt.figure(figsize = (10, 15))\n",
    "sns.countplot(y =\"store_primary_category\", data = df, order = df[\"store_primary_category\"].value_counts().index, palette = \"viridis\")\n",
    "plt.title(\"Count Plot of Store ID\")\n",
    "plt.xlabel(\"Store ID\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''A CountPlot displays the frequency of each category present in the column, in this column highest frequency of american and \n",
    "second is pizza and after that it in descending order and last one who has least frequency is alcohol-plu-food.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0b375",
   "metadata": {},
   "source": [
    "                                       6.\tMissing Values Handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e28a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\missing values.png\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870059e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.2 How can we handle missing values in the dataset, especially for important columns like store_primary_category?\n",
    "\n",
    "print(df[\"store_primary_category\"].isnull().sum())\n",
    "print(df[\"store_primary_category\"].value_counts())\n",
    "\n",
    "'''\n",
    "Since our \"store_primary_category\" already cleaned not any missing value \n",
    "present but suppose in case some missing rows there we can use the mode() \n",
    "method bcz as you can see in the columns \"american\" value has highest frequency \n",
    "and other \"chocolate\",\"alcohol-plus-food\", \"indonesian\" have the very few counts \n",
    "so in that case we can't use mean() bcz mean() is average of data\n",
    "tha't works with numerical value. if your thinking about ffill()|bfill() \n",
    "that's not useful here bcz these are most benficial in the case TimeSeries Dataset.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9026a6ea",
   "metadata": {},
   "source": [
    "                                                 7.\tCorrelation Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20298d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename= \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Correlaion.jpg\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab191a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.1 What are the Pearson and Spearman correlation coefficients between numerical features (e.g., total_items, subtotal, min_item_price, max_item_price)?\n",
    "\n",
    "numerical_features = df[[\"total_items\", \"subtotal\", \"min_item_price\", \"max_item_price\"]]\n",
    "\n",
    "# Pearson Correlation\n",
    "Pearson_corr = numerical_features.corr(method = \"pearson\")\n",
    "print(Pearson_corr)\n",
    "\n",
    "print(\"\\n\" + \"*\"*100, \"\\n\")\n",
    "\n",
    "# Spearman correlation\n",
    "Spearman_corr = numerical_features.corr(method = \"spearman\")\n",
    "print(Spearman_corr)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Peason Correlation indicates :\n",
    "\n",
    "1  For highly positive linear releationship.\n",
    "-1 For highly negative liner releationship.\n",
    "0  For no linear relationship.\n",
    "\n",
    "\n",
    "Sperman Correlation indicates : Same as the pearson correlaion but based on rank,\n",
    "                                 strength and direction of the monotonic relationship between two variables.\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deddda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.2. What do these correlations suggest?\n",
    "\n",
    "\n",
    "''' assume result as the matrix we can see that the diagonal elements of the structrue are highly correleated bcz it's correlated\n",
    "with itself and in other hand \n",
    "\n",
    "total_items positively linear correlation with \"subtotal\" and negative correlation with \"min_item_price\", \"max_item_price\" that\n",
    "means if the \"total_items\" increases then \"subtotal\" will increase and \"min_item_price\", \"max_item_price\" will decreases and also\n",
    "vice versa.\n",
    "\n",
    "'''\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc2f9b",
   "metadata": {},
   "source": [
    "                                      8. Multivariate Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e77553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename  =  \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\multivariate.png\", width =500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad36293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.1 How do multiple factors (e.g., market_id, store_primary_category, order_protocol) together influence the subtotal ?\n",
    "\n",
    "\n",
    "\n",
    "# Extracting top 5  \"store_primary_category\" bcz we have 174 unique value might be our plot will cluttered\n",
    "# for clear picture and avoid clutterness  we only extract top cateogries which have high frquency in our dataset.\n",
    "\n",
    "\n",
    "# Extracting top 5 \"store_primary_category\"\n",
    "Category_Counts = df[\"store_primary_category\"].value_counts()\n",
    "top5_Categories = Category_Counts.nlargest(5).index\n",
    "\n",
    "# creating temporary df bcz we don't wanaa change any thing our main df\n",
    "temp_df = df.copy()\n",
    "\n",
    "\n",
    "# creating new feature in temporary df\n",
    "temp_df[\"Simplified_Primary_Categories\"] = temp_df[\"store_primary_category\"].apply(lambda x : x if  x in top5_Categories else np.nan)\n",
    "\n",
    "# filterd the temp_df bcz we have null values in the temp_df is we don't eliminate it it may be more than our original top 5 categories\n",
    "filtered_df = temp_df[temp_df[\"Simplified_Primary_Categories\"].notnull()]\n",
    "\n",
    "# plotting pariplot \"market_id\", \"subtotal\", and \"order_protocol\" with bifarcation of \"Simplified_Primary_Categories\".\n",
    "sns.pairplot(filtered_df, vars = [\"market_id\", \"subtotal\", \"order_protocol\"], hue = \"Simplified_Primary_Categories\")\n",
    "plt.title(\"PairPlot Of market_id, store_primary_category and  order_protcol By Simpllified_Primary_Category\")\n",
    "             \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44acf51c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "After the observation of \"market_id\", \"subtotal\" and \"order_protocol\" fifarcation of \"top5_Categories\" \n",
    "\"market_id\" ---> The \"market_id\" indicates some data poits are concentrated around specific data points\n",
    "                showing some market has higher orders than others like \"market_d\" 1 and 2 showing hig density \n",
    "                as comparere to other market_id.\n",
    "                \n",
    "\"subtotal\" ----> The \"subtotal\" indicates most \"subtotal\" are in the lower side and few are high values.\n",
    "\"order_protocol\" ----> The \"order_protocol\" having distint peak or the randomness indicates order protocol high frequency.\n",
    "\n",
    "\n",
    "\"market_id\" VS \"subtotal\" VS \"order_protocol\" --->  showing how they are releated to each others \n",
    "                                                   \"market_id\" vs \"subtotal\" indicates some market has high subtoal but others\n",
    "                                                   having low, \"subtotal\" vs \"order_protocol\" indicates how no one protcols dominating\n",
    "                                                   means here the randomness and all the things vice-versa and all over dominating \"american\"\n",
    "                                                   bcz \"american\" having has frequency in our dataset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting 3d plot to see how \"market_id\", \"subtotal\" and \"order_protocol\" are releated to each other\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = plt.subplot(111, projection = \"3d\")\n",
    "\n",
    "ax.scatter(df[\"market_id\"], df[\"subtotal\"], df[\"order_protocol\"], color = \"green\", marker = \"o\")\n",
    "ax.set_title(\"3D plot of Market ID, Subtotal And  Order Protocol\")\n",
    "ax.set_xlabel(\"Marker ID\")\n",
    "ax.set_ylabel(\"Subtotal\")\n",
    "ax.set_zlabel(\"Order Protocol\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db309e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Q.2 How do multiple factors (e.g., market_id, store_primary_category, order_protocol) together influence the  delivery time?\n",
    "\n",
    "\n",
    "sns.pairplot(filtered_df, vars = [\"market_id\", \"TimeTakenForDelivery_Minutes\", \"order_protocol\"], hue = \"Simplified_Primary_Categories\")\n",
    "plt.title(\"PairPlot Of market_id, store_primary_category and  order_protcol By Simpllified_Primary_Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64497b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "After the observation of \"market_id\", \"subtotal\" and \"order_protocol\" fifarcation of \"top5_Categories\" \n",
    "\"market_id\" ---> The \"market_id\" indicates some data poits are concentrated around specific data points\n",
    "                showing some market has higher orders than others like \"market_d\" 1 and 2 showing hig density \n",
    "                as comparere to other market_id..\n",
    "                \n",
    "\"TimeTakeForDelivery_Minutes\" ----> most orders delivers within the 60 minutes but sandwitch delivered so fast and americal likely\n",
    "                                    late we know that bcz highest frequecy in our dataset so not be surprised.\n",
    "\"order_protocol\" ----> The \"order_protocol\" having distint peak or the randomness indicates order protocol high frequency.\n",
    "\n",
    "\n",
    "\"market_id\" VS \"subtotal\" VS \"order_protocol\" --->  showing how they are releated to each others \n",
    "                                                   and clustered in specific market as well as category.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27595b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting 3d plot to see how \"market_id\", \"TimeTakenForDelivery_Minutes\" and \"order_protocol\" are releated to each other\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax = plt.subplot(111, projection = \"3d\")\n",
    "\n",
    "ax.scatter(df[\"market_id\"], df[\"TimeTakenForDelivery_Minutes\"], df[\"order_protocol\"], color = \"red\", marker = \"o\")\n",
    "ax.set_title(\"3D plot of Market ID, Subtotal And  Order Protocol\")\n",
    "ax.set_xlabel(\"Marker ID\")\n",
    "ax.set_ylabel(\"Subtotal\")\n",
    "ax.set_zlabel(\"Order Protocol\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae66a5",
   "metadata": {},
   "source": [
    "                                      9. Outlier Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\Outlier_Detection.png\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae752e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Q. Are there any outliers in the dataset? Which method can be used to identify and handle these outliers?\n",
    "\n",
    "'''Since we alreaday remove outliers from our dataset but might be possible some outliers still remaning in the dataset.'''\n",
    "\n",
    "# We used scatterplots, boxplots, and violin plots to detect outliers. After identifying the outliers, we used the \n",
    "# IQR (Interquartile Range) method to remove them. The IQR method is generally preferred for skewed data, whereas \n",
    "# the Z-score method is typically used for normally distributed data. Therefore, we opted for the IQR method in this case.\n",
    "\n",
    "df.describe()\n",
    "\n",
    "'''Here you can see the the some field containing negative values  like \"min_item_price\" and \"total_onshift_partners\" \n",
    "it is not pratically possible so we can eliminate it and after that our dataset would cleaned.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645e9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminating negative values from \"minimum_item_price\" and \"total_onshift_partners\".\n",
    "\n",
    "df = df[df[\"min_item_price\"] >= 0]\n",
    "df = df[df[\"total_onshift_partners\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82ae9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here we can see that the no any negative value in our dataset.'''\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774e0ef5",
   "metadata": {},
   "source": [
    "                              10.\tCorrelation Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Correlation_2.png\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c71e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. What are the Pearson and Spearman correlation coefficients between numerical features (e.g., total_items, subtotal, min_item_price, max_item_price)? What do these correlations suggest?\n",
    "\n",
    "\n",
    "numerical_features = df[[\"total_items\", \"subtotal\", \"min_item_price\", \"max_item_price\"]]\n",
    "\n",
    "# Pearson Correlation\n",
    "Pearson_corr = numerical_features.corr(method = \"pearson\")\n",
    "print(Pearson_corr)\n",
    "\n",
    "print(\"\\n\" + \"*\"*100, \"\\n\")\n",
    "\n",
    "# Spearman correlation\n",
    "Spearman_corr = numerical_features.corr(method = \"spearman\")\n",
    "print(Spearman_corr)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Peason Correlation indicates :\n",
    "\n",
    "1  For highly positive linear releationship.\n",
    "-1 For highly negative liner releationship.\n",
    "0  For no linear relationship.\n",
    "\n",
    "\n",
    "Sperman Correlation indicates : Same as the pearson correlaion but based on rank,\n",
    "                                 strength and direction of the monotonic relationship between two variables.\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f18e06",
   "metadata": {},
   "source": [
    "                                              11. Multivariate Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f8632",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\multivariate_2.png\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0bf94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. How do multiple factors (e.g., market_id, store_primary_category, order_protocol) together influence the subtotal or delivery time?\n",
    "\n",
    "'''Since we've already analyzed this, there's no need to do it again.'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237adf2",
   "metadata": {},
   "source": [
    "                                           12. Outlier Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e164e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Outlier_Detection_2.png\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.  Are there any outliers in the dataset? Which method can be used to identify and handle these outliers? o How do the data distributions change after removing outliers?\n",
    "\n",
    "'''Since we've already analyzed this, there's no need to do it again.'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eded88",
   "metadata": {},
   "source": [
    "                               13. Categorical Feature Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Categorical_Encoding.jpg\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40f4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#o How can we encode categorical variables like store_primary_category and order_protocol for further analysis?\n",
    "\n",
    "Categorical_df = df[[\"store_primary_category\", \"order_protocol\"]]\n",
    "Encoded_Categorical_df = pd.get_dummies(Categorical_df, drop_first = True)\n",
    "Encoded_Categorical_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f688ad7",
   "metadata": {},
   "source": [
    "                                14.\tAdvanced Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d01ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Feature-Engineering-Feature_2.jpg\", width = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10943d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.1. Can we create a feature based on the availability of delivery partners, such as a ratio of total_busy_partners to total_onshift_partners?\n",
    "\n",
    "df[\"AvailabilityOfDeliveryPartners\"] = np.where(df[\"total_onshift_partners\"] != 0, # might there is no any \"total_onshift_partners\" i.e, 0.\n",
    "                                                   df[\"total_busy_partners\"] / df[\"total_onshift_partners\"], np.nan )\n",
    "df[\"AvailabilityOfDeliveryPartners\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.2. How do engineered features like order time of day or week enhance the predictive power or insights of the analysis?\n",
    "\n",
    "df[\"OrderTimeOfDay\"] = df[\"created_at\"].dt.time # Created new feature \"OrderTimeOfDay\"\n",
    "print(df[\"OrderTimeOfDay\"]) \n",
    "print(\"\\n\",\"*\"*100, \"\\n\")\n",
    "\n",
    "\n",
    "print(df[\"OrderTimeOfDay\"].value_counts()) # counting the highest frequecy and which time is peak at the day\n",
    "print(\"\\n\",\"*\"*100, \"\\n\")\n",
    "\n",
    "\n",
    "'''Since We already created the \"DayOfWeek\" so don't need to create it again.'''\n",
    "\n",
    "print(df[\"DayOfWeek\"]) \n",
    "\n",
    "print(\"\\n\",\"*\"*100, \"\\n\")\n",
    "\n",
    "print(df[\"DayOfWeek\"].value_counts()) # counting the highest frequecny and which DoyOfWeek at the peak orders\n",
    "\n",
    "\n",
    "'''\n",
    "After creating features like 'HourOfDay' and 'DayOfWeek', we can identify peak times during the day and \n",
    "which days of the week have the highest activity. Based on this, we will adjust our planning and, if necessary, \n",
    "hire additional staff or offer overtime to cover those peak periods.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b1deb",
   "metadata": {},
   "source": [
    "                                        12.\tAdvanced Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a026bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Data-visualization_.png\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befdbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.1. Use advanced visualization techniques (e.g., heatmaps, pair plots) to explore relationships between multiple variables simultaneously.\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    "Numerical_df = df.select_dtypes([np.number])\n",
    "corr = Numerical_df.corr()\n",
    "\n",
    "sns.heatmap(corr, annot = True, cmap = \"coolwarm\", fmt = \"0.2f\", \n",
    "           linewidth = 0.5, linecolor = \"green\", cbar_kws = {\"shrink\" : 0.8}, annot_kws = {\"size\" : 10})\n",
    "plt.title(\"Correlation Heatmap\", fontsize = 16)\n",
    "plt.xlabel(\"Features\", fontsize = 14)\n",
    "plt.ylabel(\"Features\", fontsize = 14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we can see that  correlation between all features in the heatmap \n",
    "(a). The Darker color represents the feature is highly corelated, lighter color indicates the less corelated to each other \n",
    "and white color is indicate the no corelation or the almost neglible corelation between the features.\n",
    "\n",
    "(b). The highly corelated represents with the positive (1), highly negative corelated represents with the negative (-1) \n",
    "and the neglible corelation represents with the (0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.2.How do interactions between categorical variables (e.g., store_primary_category * order_protocol) affect the delivery time?\n",
    "\n",
    "sns.pairplot(filtered_df, vars = [\"TimeTakenForDelivery_Minutes\", \"order_protocol\"], hue = \"Simplified_Primary_Categories\")\n",
    "plt.title(\"PairPlot Of market_id, store_primary_category and  order_protcol By Simpllified_Primary_Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7566ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "After the observation of \"market_id\", \"subtotal\" and \"order_protocol\" fifarcation of \"top5_Categories\" \n",
    "                \n",
    "\"TimeTakeForDelivery_Minutes\" ----> most orders delivers within the 60 minutes but sandwitch delivered so fast and americal likely\n",
    "                                    late we know that bcz highest frequecy in our dataset so not be surprised.\n",
    "\"order_protocol\" ----> The \"order_protocol\" having distint peak or the randomness indicates order protocol high frequency.\n",
    "\n",
    "\n",
    "\"TimeTakeForDelivery_Minutes\" VS \"subtotal\" VS \"order_protocol\" --->  showing how they are releated to each others \n",
    "                                                   and clustered in specific market as well as category.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f1860c",
   "metadata": {},
   "source": [
    "                                             13.\tStatistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename =\"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\PNG\\\\Statical_Analysis.png\", width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc91601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to find the \"TimeTakenForDelivery_Minutes\", \"store_primary_category\" and \"order_protocol\" are normally distributed or not.\n",
    "\n",
    "fig, axes  = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "# \"TimeTakenForDelivery_Minutes\" looks normally distributed it's seems peak around 40 minutes mark and tapers off toward both ends\n",
    "# Both tails of histogram are releatively balanced which is another of normality.\n",
    "sns.histplot(x = df[\"TimeTakenForDelivery_Minutes\"], kde = True, bins = 5, ax = axes[0])\n",
    "axes[0].set_title(\"Histplot Of Time Taken For Delivery_Minutes\")\n",
    "\n",
    "\n",
    "\n",
    "# \"store_primary_category\" historgram appear quite irregular and not resemble the normal distribution data contain multiple\n",
    "# peaks it's shows data are multimodal distribution rather than normal distribution.\n",
    "sns.histplot(x = df[\"store_primary_category\"], kde = True, bins = 5, ax = axes[1])\n",
    "axes[1].set_title(\"Histplot Of Store Primary Category\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# it's also indicate the data is not normally distributed containing multiple distict peak representing multimodal distribution.\n",
    "sns.histplot(x = df[\"order_protocol\"], kde = True, bins = 5, ax = axes[2])\n",
    "axes[2].set_title(\"Histplot Of Order Protocol\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"TimeTakenForDelivery_Minutes\" might not be normal distribution so we  can confirm it by shapiro test\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p = shapiro(df[\"TimeTakenForDelivery_Minutes\"])\n",
    "print(f\"statics : {stat:.3f},  p-value :{p:.3f}\")\n",
    "\n",
    "if p < 0.05 :\n",
    "    print(\"Sample doesn't look normally distruted (reject H0)\")\n",
    "else :\n",
    "    print(\"Sample look normally distributed (fail to reject H0)\")\n",
    "\n",
    "\n",
    "'''Now we confirmed it \"TimeTakenForDelivery_Minutes\" column doesn't normally distributed.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32caac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#.Q.1.Perform statistical tests to determine if there are significant differences in delivery times between different groups (e.g., different restaurant categories or order protocols).\n",
    "\n",
    "'''Since our all three columns aren't normally distributed so we can go with  Kruskal-Wallis test.'''\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# performing test for \"store_primary_category\"\n",
    "kruskal_result = kruskal(\n",
    "    *(df[df[\"store_primary_category\"] == category][\"TimeTakenForDelivery_Minutes\"]\n",
    "     for category in df[\"store_primary_category\"].unique())\n",
    " )\n",
    "\n",
    "print(kruskal_result)\n",
    "print(\"\\n\",\"*\"*100,\"\\n\")\n",
    "\n",
    "if kruskal_result.pvalue  < 0.05 :\n",
    "    print(\"sample look normally distributed : (fail to reject H0)\")  # something is happeing or difference \n",
    "else:\n",
    "    print(\"sample doesn't look normally distributed : (reject H0)\") # represent no effect or no difference\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "'''suppose if we receive \"fail ot reject H0\" means the there are  differnece between delivery time in \"american\" category and \"burger\" category '''\n",
    "\n",
    "'''suppose if we receive \"reject H0\" means the there aren't  differnece between delivery time in \"american\" category and \"burger\" category '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95905053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#.Q.2.Perform statistical tests to determine if there are significant differences in delivery times between different groups (e.g., different restaurant categories or order protocols).\n",
    "\n",
    "#performing test for \"order_protocol\"\n",
    "kruskal_result = kruskal(\n",
    "                    *(df[df[\"order_protocol\"] == category][\"TimeTakenForDelivery_Minutes\"]\n",
    "                     for category in df[\"order_protocol\"].unique())\n",
    ")\n",
    "\n",
    "\n",
    "print(kruskal_result)\n",
    "print(\"\\n\",\"*\"*100,\"\\n\")\n",
    "\n",
    "if kruskal_result.pvalue < 0.05 :\n",
    "    print(\"Sample look normally distributed : (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"Sample doesn't look normally distributed : (reject H0)\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "'''\n",
    "suppose if we receive \"fail ot reject H0\" means the there are  differnece between delivery time in \"order_protocol :1\" and \"order_protocol :2\" \n",
    "\n",
    "suppose if we receive \"reject H0\" means the there aren't differnece between delivery time in \"order_protocol :1\" and \"order_protocol :2\" \n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce51ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''I have completed all the tasks outlined in the document to the best of my knowledge and expertise. \n",
    "If anything was missed or if there are any inaccuracies in the analysis, I welcome your feedback and suggestions for improvement.\n",
    "\n",
    "I thoroughly enjoyed working on this project, as it allowed me to revisit and apply various concepts.\n",
    "\n",
    "Thank you, Team CloudML, for creating such an engaging project and giving me the opportunity to work on it.\n",
    "\n",
    "Sincerely,\n",
    "A Happy Learner'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f59440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec242d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Mustafa Hussain\\\\Desktop\\\\Placement Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe91f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Cleaned Porter Dataset.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Cleaned Porter Dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90454ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Cleaned_Porter_Dataset.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e94654",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f91849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel(\"Cleaned Porter Dataset.xlsx\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
